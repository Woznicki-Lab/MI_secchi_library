{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tidy data"
      ],
      "metadata": {
        "id": "A5LjBB5HECZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHsvHosYD8og"
      },
      "outputs": [],
      "source": [
        "# import ee\n",
        "# !pip install geopandas geemap geehydro\n",
        "# import geemap\n",
        "# import folium\n",
        "# import geehydro\n",
        "\n",
        "# try:\n",
        "#         ee.Initialize()\n",
        "# except Exception as e:\n",
        "#         ee.Authenticate()\n",
        "#         ee.Initialize()\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import numpy as np\n",
        "import io\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['MAIN_S2_secchilakes_stats.csv']))\n",
        "\n",
        "#remove index and geometry columns\n",
        "df1 = df.iloc[0:,2: ]"
      ],
      "metadata": {
        "id": "ENACN4XjQV69",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from pandas.tseries.offsets import Day\n",
        "import numpy as np\n",
        "test = df1.melt(['STORETID', 'COUNT_STOR', 'MEAN_Latit', 'MEAN_Longi'], var_name = \"imageID\", value_name = \"values\")\n",
        "test = test.dropna()\n",
        "test[[\"satellite\", \"date\", \"delete_date\", \"tile\", \"band\"]] = test[\"imageID\"].str.split('_', expand=True)\n",
        "test = test.drop(['delete_date', 'imageID'], axis=1)\n",
        "test[[\"capture_date\", \"delete\"]] = test[\"date\"].str.split('T', expand=True)\n",
        "test = test.drop(['date', 'delete'], axis=1)\n",
        "test[\"capture_date\"] = pd.to_datetime(test[\"capture_date\"], format='%Y%m%d')\n",
        "test[\"date_max\"] = test[\"capture_date\"] + pd.Timedelta(days=7)\n",
        "test[\"date_min\"] = test[\"capture_date\"] - pd.Timedelta(days=7)\n",
        "\n",
        "#remove duplicates\n",
        "# test = test.round(decimals=5)\n",
        "test = test.drop_duplicates(keep='first')\n",
        "\n",
        "test = test.pivot_table(values='values',\n",
        "                        index=['STORETID', 'COUNT_STOR', 'MEAN_Latit', 'MEAN_Longi', 'satellite', 'tile', 'date_max', 'capture_date', 'date_min'],\n",
        "                        columns=['band'],\n",
        "                        aggfunc='mean').reset_index()\n",
        "\n",
        "\n",
        "data_table.DataTable(test, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "nuMIeFjHgFk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in *in situ* data"
      ],
      "metadata": {
        "id": "LtGRxl9BAuMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded2 = files.upload()\n",
        "meas_sd = pd.read_csv(io.BytesIO(uploaded2['mi_secchi_V3.csv']))[[\"STORETID\", \"Date Sampled\", \"secchi_m\"]]\n",
        "meas_sd['Date Sampled'] = pd.to_datetime(meas_sd['Date Sampled'], format = '%Y-%m-%d')\n",
        "data_table.DataTable(meas_sd, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "wOlZfFTPHYr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_merge = test.merge(meas_sd,on='STORETID',how='left')\n",
        "data_table.DataTable(test_merge, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "G0HZhefMRSJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_merge_filt = test_merge[(test_merge['Date Sampled'] > test_merge['date_min']) & (test_merge['Date Sampled'] < test_merge['date_max'])].reset_index()\n",
        "test_merge_filt = test_merge_filt.drop(['index'], axis=1)\n",
        "data_table.DataTable(test_merge_filt, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "sap9rP0URxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(test_merge_filt)\n",
        "df2 = df.drop_duplicates(subset=['STORETID', 'Date Sampled'], keep=False)\n",
        "data_table.DataTable(df2, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "bvbPE5WZuu5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = os.path.expanduser('~/Downloads')\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "\n",
        "output_filepath = os.path.join(out_dir, 'sentinel_micorps_joined_V4.csv')\n",
        "df2.to_csv(output_filepath)"
      ],
      "metadata": {
        "id": "llByJxCDuZTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}